{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9386030,"sourceType":"datasetVersion","datasetId":5694818}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-14T12:12:56.491824Z","iopub.execute_input":"2024-09-14T12:12:56.492214Z","iopub.status.idle":"2024-09-14T12:12:56.511371Z","shell.execute_reply.started":"2024-09-14T12:12:56.492177Z","shell.execute_reply":"2024-09-14T12:12:56.510309Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/real-test-data/dataset/sample_test.csv\n/kaggle/input/real-test-data/dataset/sample_test_out_fail.csv\n/kaggle/input/real-test-data/dataset/sample_test_out.csv\n/kaggle/input/real-test-data/dataset/train.csv\n/kaggle/input/real-test-data/dataset/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# OUTLINE \n* Load the image dataset.\n* Apply OCR using EasyOCR with preprocessing (e.g., grayscale conversion, thresholding).\n* Clean common OCR mistakes.\n* Generate a final DataFrame with metadata.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/real-test-data/dataset/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:12:56.512918Z","iopub.execute_input":"2024-09-14T12:12:56.513221Z","iopub.status.idle":"2024-09-14T12:12:56.836438Z","shell.execute_reply.started":"2024-09-14T12:12:56.513190Z","shell.execute_reply":"2024-09-14T12:12:56.835359Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:12:56.837722Z","iopub.execute_input":"2024-09-14T12:12:56.838123Z","iopub.status.idle":"2024-09-14T12:12:56.904928Z","shell.execute_reply.started":"2024-09-14T12:12:56.838081Z","shell.execute_reply":"2024-09-14T12:12:56.903822Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 131187 entries, 0 to 131186\nData columns (total 4 columns):\n #   Column       Non-Null Count   Dtype \n---  ------       --------------   ----- \n 0   index        131187 non-null  int64 \n 1   image_link   131187 non-null  object\n 2   group_id     131187 non-null  int64 \n 3   entity_name  131187 non-null  object\ndtypes: int64(2), object(2)\nmemory usage: 4.0+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Key Fix:\n* Convert Pillow Image to Numpy Array: In the perform_ocr() function, the grayscale Pillow image is now converted to a numpy array using np.array(preprocessed_image) before passing it to EasyOCR","metadata":{}},{"cell_type":"code","source":"import requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport easyocr\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=False)\n\n# Sample image URL\nimage_url = \"https://m.media-amazon.com/images/I/81bLHedrwL._AC_SL1500_.jpg\"\n\n# Function to preprocess and display the image\ndef preprocess_image(image_url):\n    try:\n        # Send a request to get the image from the URL\n        response = requests.get(image_url)\n        response.raise_for_status()  # Ensure the request was successful\n        \n        # Open the image and convert it to grayscale\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Display the image\n        plt.imshow(gray_img, cmap='gray')\n        plt.axis('off')  # Turn off the axis\n        plt.show()\n        \n        return gray_img\n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return None\n\n# Preprocess and display the image\npreprocessed_image = preprocess_image(image_url)\n\n# Perform OCR if the image was processed successfully\nif preprocessed_image:\n    # Convert Pillow image to numpy array\n    np_image = np.array(preprocessed_image)\n    \n    # Perform OCR using EasyOCR\n    result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n    extracted_text = \" \".join(result)  # Join the OCR result into a single string\n    print(extracted_text)\nelse:\n    print(\"Error processing image\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:12:56.907778Z","iopub.execute_input":"2024-09-14T12:12:56.908201Z","iopub.status.idle":"2024-09-14T12:13:00.058074Z","shell.execute_reply.started":"2024-09-14T12:12:56.908155Z","shell.execute_reply":"2024-09-14T12:13:00.057074Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(model_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Error downloading image from https://m.media-amazon.com/images/I/81bLHedrwL._AC_SL1500_.jpg: 400 Client Error: Bad Request for url: https://m.media-amazon.com/images/I/81bLHedrwL._AC_SL1500_.jpg\nError processing image\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\n\ndef extract_weight(text):\n    # Regular expression pattern to match item weights (e.g., \"90 lb\", \"160gms\", \"160 grams\")\n    weight_pattern = r\"(\\d+)\\s?(lb|gms|grams|kg|kilograms)\"\n    \n    # Search for all matches in the text\n    matches = re.findall(weight_pattern, text, re.IGNORECASE)\n    \n    # Prepare a list to store formatted weights\n    weights = []\n    \n    # Process each match to clean up the format\n    for match in matches:\n        weight_value, weight_unit = match\n        weight_value = weight_value.strip()  # Remove extra spaces\n        weight_unit = weight_unit.lower()    # Normalize units to lower case\n        weights.append(f\"{weight_value} {weight_unit}\")\n\n    # Return list of extracted weights\n    return weights\n\n# Example usage with series of text data\ntexts = [\n    \"sfdf height fksdj weight hdf 76 lbs 22lbs\" ]\n\n# Iterate over texts and extract weights\nfor i, text in enumerate(texts, start=1):\n    extracted_weights = extract_weight(text)\n    print(f\"Text {i} - Extracted Weights: {extracted_weights}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.059120Z","iopub.execute_input":"2024-09-14T12:13:00.059411Z","iopub.status.idle":"2024-09-14T12:13:00.067218Z","shell.execute_reply.started":"2024-09-14T12:13:00.059381Z","shell.execute_reply":"2024-09-14T12:13:00.066155Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Text 1 - Extracted Weights: ['76 lb', '22 lb']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# BASIC PREPROCESSING\n* Sort the CSV by the entity_name column alphabetically.\n* Create separate dataframes for each unique entity_name.\n* Ensure that the total number of rows remains intact across all separate dataframes.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV data into a pandas DataFrame (replace 'your_csv_file.csv' with your actual CSV file path)\ndata = pd.read_csv('your_csv_file.csv')\n\n# Step 1: Sort the dataframe by the 'entity_name' column alphabetically\nsorted_data = data.sort_values(by='entity_name')\n\n# Step 2: Create separate dataframes for each unique 'entity_name'\ngrouped_dfs = {entity: sorted_data[sorted_data['entity_name'] == entity] for entity in sorted_data['entity_name'].unique()}\n\n# Step 3: Verify the total number of rows in all separate dataframes is equal to the original dataframe\ntotal_rows = sum([len(df) for df in grouped_dfs.values()])\noriginal_rows = len(sorted_data)\n\n# Check if the number of rows is intact\nif total_rows == original_rows:\n    print(\"The total number of rows is intact!\")\nelse:\n    print(f\"Row mismatch: {total_rows} rows in separate dataframes, {original_rows} rows in original dataframe.\")\n\n# Optional: Display or use the separate dataframes\nfor entity, df in grouped_dfs.items():\n    print(f\"Dataframe for entity '{entity}':\")\n    print(df, \"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.068358Z","iopub.execute_input":"2024-09-14T12:13:00.068706Z","iopub.status.idle":"2024-09-14T12:13:00.235512Z","shell.execute_reply.started":"2024-09-14T12:13:00.068673Z","shell.execute_reply":"2024-09-14T12:13:00.232757Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the CSV data into a pandas DataFrame (replace 'your_csv_file.csv' with your actual CSV file path)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_csv_file.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 1: Sort the dataframe by the 'entity_name' column alphabetically\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sorted_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_csv_file.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'your_csv_file.csv'","output_type":"error"}]},{"cell_type":"markdown","source":"# Load the CSV data into a pandas DataFrame (replace 'your_csv_file.csv' with your actual CSV file path)","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/real-test-data/dataset/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:30.324883Z","iopub.execute_input":"2024-09-14T12:13:30.325908Z","iopub.status.idle":"2024-09-14T12:13:30.511121Z","shell.execute_reply.started":"2024-09-14T12:13:30.325852Z","shell.execute_reply":"2024-09-14T12:13:30.510090Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Sort the dataframe by the 'entity_name' column alphabetically","metadata":{}},{"cell_type":"code","source":"sorted_data = data.sort_values(by='entity_name')\nsorted_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:34.420566Z","iopub.execute_input":"2024-09-14T12:13:34.420940Z","iopub.status.idle":"2024-09-14T12:13:34.574209Z","shell.execute_reply.started":"2024-09-14T12:13:34.420904Z","shell.execute_reply":"2024-09-14T12:13:34.573230Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       index                                         image_link  group_id  \\\n47896  47943  https://m.media-amazon.com/images/I/51Tj2jPW0v...    296275   \n38494  38538  https://m.media-amazon.com/images/I/51JU5+OZWN...    648011   \n21600  21630  https://m.media-amazon.com/images/I/510y3mbpLx...    866516   \n60216  60268  https://m.media-amazon.com/images/I/51hE0fs44f...    488964   \n21598  21628  https://m.media-amazon.com/images/I/510y02x7cM...    453674   \n\n      entity_name  \n47896       depth  \n38494       depth  \n21600       depth  \n60216       depth  \n21598       depth  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_link</th>\n      <th>group_id</th>\n      <th>entity_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47896</th>\n      <td>47943</td>\n      <td>https://m.media-amazon.com/images/I/51Tj2jPW0v...</td>\n      <td>296275</td>\n      <td>depth</td>\n    </tr>\n    <tr>\n      <th>38494</th>\n      <td>38538</td>\n      <td>https://m.media-amazon.com/images/I/51JU5+OZWN...</td>\n      <td>648011</td>\n      <td>depth</td>\n    </tr>\n    <tr>\n      <th>21600</th>\n      <td>21630</td>\n      <td>https://m.media-amazon.com/images/I/510y3mbpLx...</td>\n      <td>866516</td>\n      <td>depth</td>\n    </tr>\n    <tr>\n      <th>60216</th>\n      <td>60268</td>\n      <td>https://m.media-amazon.com/images/I/51hE0fs44f...</td>\n      <td>488964</td>\n      <td>depth</td>\n    </tr>\n    <tr>\n      <th>21598</th>\n      <td>21628</td>\n      <td>https://m.media-amazon.com/images/I/510y02x7cM...</td>\n      <td>453674</td>\n      <td>depth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"\n# Step 2: Create separate dataframes for each unique 'entity_name'","metadata":{}},{"cell_type":"code","source":"grouped_dfs = {entity: sorted_data[sorted_data['entity_name'] == entity] for entity in sorted_data['entity_name'].unique()}","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:38.420696Z","iopub.execute_input":"2024-09-14T12:13:38.421574Z","iopub.status.idle":"2024-09-14T12:13:38.602961Z","shell.execute_reply.started":"2024-09-14T12:13:38.421533Z","shell.execute_reply":"2024-09-14T12:13:38.602176Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: Verify the total number of rows in all separate dataframes is equal to the original dataframe","metadata":{}},{"cell_type":"code","source":"total_rows = sum([len(df) for df in grouped_dfs.values()])\noriginal_rows = len(sorted_data)\nprint(total_rows)\nprint(original_rows)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:41.914078Z","iopub.execute_input":"2024-09-14T12:13:41.914455Z","iopub.status.idle":"2024-09-14T12:13:41.919894Z","shell.execute_reply.started":"2024-09-14T12:13:41.914418Z","shell.execute_reply":"2024-09-14T12:13:41.918979Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"131187\n131187\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Check if the number of rows is intact","metadata":{}},{"cell_type":"code","source":"if total_rows == original_rows:\n    print(\"The total number of rows is intact!\")\nelse:\n    print(f\"Row mismatch: {total_rows} rows in separate dataframes, {original_rows} rows in original dataframe.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:45.100556Z","iopub.execute_input":"2024-09-14T12:13:45.101172Z","iopub.status.idle":"2024-09-14T12:13:45.106249Z","shell.execute_reply.started":"2024-09-14T12:13:45.101134Z","shell.execute_reply":"2024-09-14T12:13:45.105319Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"The total number of rows is intact!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Optional: Display or use the separate dataframes","metadata":{}},{"cell_type":"code","source":"for entity, df in grouped_dfs.items():\n    print(f\"Dataframe for entity '{entity}':\")\n    print(df, \"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:47.571196Z","iopub.execute_input":"2024-09-14T12:13:47.571843Z","iopub.status.idle":"2024-09-14T12:13:47.601215Z","shell.execute_reply.started":"2024-09-14T12:13:47.571805Z","shell.execute_reply":"2024-09-14T12:13:47.600194Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Dataframe for entity 'depth':\n       index                                         image_link  group_id  \\\n47896  47943  https://m.media-amazon.com/images/I/51Tj2jPW0v...    296275   \n38494  38538  https://m.media-amazon.com/images/I/51JU5+OZWN...    648011   \n21600  21630  https://m.media-amazon.com/images/I/510y3mbpLx...    866516   \n60216  60268  https://m.media-amazon.com/images/I/51hE0fs44f...    488964   \n21598  21628  https://m.media-amazon.com/images/I/510y02x7cM...    453674   \n...      ...                                                ...       ...   \n9317    9328  https://m.media-amazon.com/images/I/41Qqaynypv...    752266   \n94549  94623  https://m.media-amazon.com/images/I/618CGovZ6i...    529606   \n94534  94608  https://m.media-amazon.com/images/I/618Bl445n5...    430434   \n54179  54226  https://m.media-amazon.com/images/I/51aZrdA52Z...    927393   \n10953  10965  https://m.media-amazon.com/images/I/41Wic7r39W...    594224   \n\n      entity_name  \n47896       depth  \n38494       depth  \n21600       depth  \n60216       depth  \n21598       depth  \n...           ...  \n9317        depth  \n94549       depth  \n94534       depth  \n54179       depth  \n10953       depth  \n\n[28146 rows x 4 columns] \n\nDataframe for entity 'height':\n       index                                         image_link  group_id  \\\n61483  61535  https://m.media-amazon.com/images/I/51ia7peapq...    784538   \n52623  52670  https://m.media-amazon.com/images/I/51Yu-2XJMy...    521308   \n49163  49210  https://m.media-amazon.com/images/I/51V9YFkn1q...    579652   \n61515  61567  https://m.media-amazon.com/images/I/51icU9g7Pm...    721522   \n49136  49183  https://m.media-amazon.com/images/I/51V7nkprpS...    178958   \n...      ...                                                ...       ...   \n47309  47356  https://m.media-amazon.com/images/I/51T3ptSIp8...    558806   \n42419  42464  https://m.media-amazon.com/images/I/51Nma1LtsS...    652661   \n40927  40972  https://m.media-amazon.com/images/I/51M760ragJ...    483370   \n43683  43729  https://m.media-amazon.com/images/I/51P4vhZPeh...    886874   \n45753  45799  https://m.media-amazon.com/images/I/51RNtk+Jyn...    536334   \n\n      entity_name  \n61483      height  \n52623      height  \n49163      height  \n61515      height  \n49136      height  \n...           ...  \n47309      height  \n42419      height  \n40927      height  \n43683      height  \n45753      height  \n\n[32282 rows x 4 columns] \n\nDataframe for entity 'item_volume':\n         index                                         image_link  group_id  \\\n128423  128522  https://m.media-amazon.com/images/I/81bgTNB4g-...    257505   \n128402  128501  https://m.media-amazon.com/images/I/81bLHedrwL...    426449   \n114949  115029  https://m.media-amazon.com/images/I/711dIDwDuJ...    142295   \n41313    41358  https://m.media-amazon.com/images/I/51MVfM5NJV...    588284   \n112115  112194  https://m.media-amazon.com/images/I/61jCNOENUw...    784861   \n...        ...                                                ...       ...   \n128603  128702  https://m.media-amazon.com/images/I/81e9QD-PgV...    608041   \n121281  121371  https://m.media-amazon.com/images/I/71bVRJ9oxX...    658034   \n117209  117289  https://m.media-amazon.com/images/I/71EqFVH31e...    271722   \n120104  120190  https://m.media-amazon.com/images/I/71UxPUXle2...    162326   \n129628  129729  https://m.media-amazon.com/images/I/81t92lwnUy...    658034   \n\n        entity_name  \n128423  item_volume  \n128402  item_volume  \n114949  item_volume  \n41313   item_volume  \n112115  item_volume  \n...             ...  \n128603  item_volume  \n121281  item_volume  \n117209  item_volume  \n120104  item_volume  \n129628  item_volume  \n\n[3833 rows x 4 columns] \n\nDataframe for entity 'item_weight':\n         index                                         image_link  group_id  \\\n97353    97427  https://m.media-amazon.com/images/I/619s6EgNpQ...    288715   \n18330    18350  https://m.media-amazon.com/images/I/41y5IjnNcp...    993359   \n125703  125799  https://m.media-amazon.com/images/I/810zM6IKrJ...    853009   \n7315      7325  https://m.media-amazon.com/images/I/41JdMefJY6...    411423   \n125705  125801  https://m.media-amazon.com/images/I/811++g8RfP...    853009   \n...        ...                                                ...       ...   \n65223    65282  https://m.media-amazon.com/images/I/51mjWKSVv9...    641642   \n37278    37322  https://m.media-amazon.com/images/I/51IDg-0XvH...    939587   \n35461    35503  https://m.media-amazon.com/images/I/51G7Kpge+s...    219211   \n35644    35686  https://m.media-amazon.com/images/I/51GIVK8jyz...    130591   \n26861    26895  https://m.media-amazon.com/images/I/516mgU74QA...    130591   \n\n        entity_name  \n97353   item_weight  \n18330   item_weight  \n125703  item_weight  \n7315    item_weight  \n125705  item_weight  \n...             ...  \n65223   item_weight  \n37278   item_weight  \n35461   item_weight  \n35644   item_weight  \n26861   item_weight  \n\n[22032 rows x 4 columns] \n\nDataframe for entity 'maximum_weight_recommendation':\n         index                                         image_link  group_id  \\\n119549  119631  https://m.media-amazon.com/images/I/71RyX28mY0...    721522   \n110368  110447  https://m.media-amazon.com/images/I/61VsYM0uko...    254962   \n119420  119502  https://m.media-amazon.com/images/I/71RGzQQo62...    530318   \n114342  114422  https://m.media-amazon.com/images/I/61zsndJrsQ...    130591   \n114349  114429  https://m.media-amazon.com/images/I/61zvRTITyL...    272691   \n...        ...                                                ...       ...   \n54176    54223  https://m.media-amazon.com/images/I/51aZdaTMPM...    462757   \n40892    40937  https://m.media-amazon.com/images/I/51M5CZmHqv...    442321   \n54772    54819  https://m.media-amazon.com/images/I/51bBeUxIoP...    564709   \n54177    54224  https://m.media-amazon.com/images/I/51aZoAoKwb...    152339   \n515        515  https://m.media-amazon.com/images/I/31I6dyYENh...    569206   \n\n                          entity_name  \n119549  maximum_weight_recommendation  \n110368  maximum_weight_recommendation  \n119420  maximum_weight_recommendation  \n114342  maximum_weight_recommendation  \n114349  maximum_weight_recommendation  \n...                               ...  \n54176   maximum_weight_recommendation  \n40892   maximum_weight_recommendation  \n54772   maximum_weight_recommendation  \n54177   maximum_weight_recommendation  \n515     maximum_weight_recommendation  \n\n[7028 rows x 4 columns] \n\nDataframe for entity 'voltage':\n         index                                         image_link  group_id  \\\n7341      7351  https://m.media-amazon.com/images/I/41JiuptMlt...    883833   \n5189      5199  https://m.media-amazon.com/images/I/41CF0fdlN+...    306956   \n4374      4383  https://m.media-amazon.com/images/I/419JR5jeHM...    709627   \n109582  109661  https://m.media-amazon.com/images/I/61Ps6wOE5Z...    983323   \n7639      7649  https://m.media-amazon.com/images/I/41Kv3c2A8C...    187993   \n...        ...                                                ...       ...   \n114018  114098  https://m.media-amazon.com/images/I/61xT8cgsOt...    240413   \n64092    64149  https://m.media-amazon.com/images/I/51lSaANFZF...    641642   \n117882  117962  https://m.media-amazon.com/images/I/71Icf-T9F6...    240413   \n75104    75170  https://m.media-amazon.com/images/I/51xcpMh2Ns...    709627   \n13458    13470  https://m.media-amazon.com/images/I/41fmtT4yr4...    507467   \n\n       entity_name  \n7341       voltage  \n5189       voltage  \n4374       voltage  \n109582     voltage  \n7639       voltage  \n...            ...  \n114018     voltage  \n64092      voltage  \n117882     voltage  \n75104      voltage  \n13458      voltage  \n\n[5488 rows x 4 columns] \n\nDataframe for entity 'wattage':\n         index                                         image_link  group_id  \\\n130655  130756  https://m.media-amazon.com/images/I/91SrZrnsN+...    219211   \n44813    44859  https://m.media-amazon.com/images/I/51QMH9FyBs...    219211   \n126738  126834  https://m.media-amazon.com/images/I/81FBErFQ51...    219211   \n126742  126838  https://m.media-amazon.com/images/I/81FKV42rmq...    892291   \n130491  130592  https://m.media-amazon.com/images/I/91I9lLWK6N...    955292   \n...        ...                                                ...       ...   \n26021    26055  https://m.media-amazon.com/images/I/515oXVDqE5...    860821   \n95248    95322  https://m.media-amazon.com/images/I/618cxOx-If...    983323   \n7624      7634  https://m.media-amazon.com/images/I/41Kqby15Hf...    957050   \n20650    20677  https://m.media-amazon.com/images/I/51-zphG54v...    983323   \n74019    74085  https://m.media-amazon.com/images/I/51wNv3vFDE...    306956   \n\n       entity_name  \n130655     wattage  \n44813      wattage  \n126738     wattage  \n126742     wattage  \n130491     wattage  \n...            ...  \n26021      wattage  \n95248      wattage  \n7624       wattage  \n20650      wattage  \n74019      wattage  \n\n[5447 rows x 4 columns] \n\nDataframe for entity 'width':\n       index                                         image_link  group_id  \\\n56503  56552  https://m.media-amazon.com/images/I/51d4m+C5Ji...    464488   \n89005  89077  https://m.media-amazon.com/images/I/614xDSEOgl...    487566   \n56980  57029  https://m.media-amazon.com/images/I/51dcIAnZoH...    846116   \n89341  89413  https://m.media-amazon.com/images/I/6157urSvjY...    913156   \n88655  88727  https://m.media-amazon.com/images/I/614ka0V7L2...    292475   \n...      ...                                                ...       ...   \n74590  74656  https://m.media-amazon.com/images/I/51x-yzqwPt...    751532   \n65077  65136  https://m.media-amazon.com/images/I/51mZjubhVv...    969033   \n74589  74655  https://m.media-amazon.com/images/I/51x-yWLJdB...    306956   \n74595  74661  https://m.media-amazon.com/images/I/51x0HFBlJp...    881883   \n21256  21283  https://m.media-amazon.com/images/I/510cTWgPbZ...    478357   \n\n      entity_name  \n56503       width  \n89005       width  \n56980       width  \n89341       width  \n88655       width  \n...           ...  \n74590       width  \n65077       width  \n74589       width  \n74595       width  \n21256       width  \n\n[26931 rows x 4 columns] \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save each dataframe to a separate CSV file","metadata":{}},{"cell_type":"code","source":"\nfor entity, df in grouped_dfs.items():\n    # Create a valid file name (remove any special characters or spaces)\n    file_name = f\"{entity}_data.csv\".replace(\" \", \"_\")\n    \n    # Save the dataframe as a CSV file\n    df.to_csv(file_name, index=False)\n    print(f\"Saved dataframe for entity '{entity}' to '{file_name}'\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:55.855331Z","iopub.execute_input":"2024-09-14T12:13:55.856299Z","iopub.status.idle":"2024-09-14T12:13:56.421005Z","shell.execute_reply.started":"2024-09-14T12:13:55.856258Z","shell.execute_reply":"2024-09-14T12:13:56.420095Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Saved dataframe for entity 'depth' to 'depth_data.csv'\nSaved dataframe for entity 'height' to 'height_data.csv'\nSaved dataframe for entity 'item_volume' to 'item_volume_data.csv'\nSaved dataframe for entity 'item_weight' to 'item_weight_data.csv'\nSaved dataframe for entity 'maximum_weight_recommendation' to 'maximum_weight_recommendation_data.csv'\nSaved dataframe for entity 'voltage' to 'voltage_data.csv'\nSaved dataframe for entity 'wattage' to 'wattage_data.csv'\nSaved dataframe for entity 'width' to 'width_data.csv'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1)Wattage\n# 2)Volatge\n# 3)Maximum Weight Recommendation\n# 4)Item volume","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the 'depth_data.csv' file\nitem_volume_df = pd.read_csv('item_volume_data.csv')\n\n# Display the top 5 rows of the 'depth_data.csv'\nprint(item_volume_df.head(10))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:14:01.348201Z","iopub.execute_input":"2024-09-14T12:14:01.348601Z","iopub.status.idle":"2024-09-14T12:14:01.364745Z","shell.execute_reply.started":"2024-09-14T12:14:01.348563Z","shell.execute_reply":"2024-09-14T12:14:01.363754Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"    index                                         image_link  group_id  \\\n0  128522  https://m.media-amazon.com/images/I/81bgTNB4g-...    257505   \n1  128501  https://m.media-amazon.com/images/I/81bLHedrwL...    426449   \n2  115029  https://m.media-amazon.com/images/I/711dIDwDuJ...    142295   \n3   41358  https://m.media-amazon.com/images/I/51MVfM5NJV...    588284   \n4  112194  https://m.media-amazon.com/images/I/61jCNOENUw...    784861   \n5  127237  https://m.media-amazon.com/images/I/81KSiBGcmW...    589528   \n6  114978  https://m.media-amazon.com/images/I/711EbPu-Nh...    417442   \n7  127232  https://m.media-amazon.com/images/I/81KOZGbVZB...    125148   \n8  127456  https://m.media-amazon.com/images/I/81N6CnmBpr...    162326   \n9  112191  https://m.media-amazon.com/images/I/61j9aDDdjD...    472418   \n\n   entity_name  \n0  item_volume  \n1  item_volume  \n2  item_volume  \n3  item_volume  \n4  item_volume  \n5  item_volume  \n6  item_volume  \n7  item_volume  \n8  item_volume  \n9  item_volume  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Display rows from index 10 to 20 (note that iloc is zero-indexed)\nprint(item_volume_df.iloc[10:21])  # 10th to 20th rows, including row at index 20\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:14:06.165504Z","iopub.execute_input":"2024-09-14T12:14:06.166298Z","iopub.status.idle":"2024-09-14T12:14:06.173102Z","shell.execute_reply.started":"2024-09-14T12:14:06.166261Z","shell.execute_reply":"2024-09-14T12:14:06.172198Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"     index                                         image_link  group_id  \\\n10   45081  https://m.media-amazon.com/images/I/51Qb3xsnqj...    961822   \n11  127477  https://m.media-amazon.com/images/I/81NLC-MbzN...    911827   \n12  111793  https://m.media-amazon.com/images/I/61g-R0dUWv...    373285   \n13  112234  https://m.media-amazon.com/images/I/61jWtTCGOF...    588284   \n14  114989  https://m.media-amazon.com/images/I/711JmTEgBU...    692827   \n15  128678  https://m.media-amazon.com/images/I/81dup5ucjW...    976920   \n16  111771  https://m.media-amazon.com/images/I/61fwkjqJ0m...    941694   \n17  121564  https://m.media-amazon.com/images/I/71cjjOrq97...    142295   \n18  111742  https://m.media-amazon.com/images/I/61fn0eiL6F...    287137   \n19   63256  https://m.media-amazon.com/images/I/51kWTG56Jd...    941694   \n20  112264  https://m.media-amazon.com/images/I/61jnmb4d4J...    693967   \n\n    entity_name  \n10  item_volume  \n11  item_volume  \n12  item_volume  \n13  item_volume  \n14  item_volume  \n15  item_volume  \n16  item_volume  \n17  item_volume  \n18  item_volume  \n19  item_volume  \n20  item_volume  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# PROCESS FOR ITEM_VOLUME(3833 ROWS)","metadata":{}},{"cell_type":"markdown","source":"*  We can loop through each row of your item_volume dataframe,\n* download the image using the image_link, perform OCR on the image to extract the text, \n* and then extract only the value + unit (like \"5 liters\", \"12 cm³\", etc.).\n* If no value + unit is found in the OCR result, we will return a blank (\" \").","metadata":{}},{"cell_type":"code","source":"import requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport numpy as np\nimport pandas as pd\nimport easyocr\nimport re\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=True)\n\n# Function to preprocess and perform OCR on the image URL\ndef extract_value_unit_from_image(image_url):\n    try:\n        # Send a request to get the image from the URL\n        response = requests.get(image_url)\n        response.raise_for_status()  # Ensure the request was successful\n\n        # Open the image and convert it to grayscale\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Convert Pillow image to numpy array for OCR\n        np_image = np.array(gray_img)\n        \n        # Perform OCR using EasyOCR\n        result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n        extracted_text = \" \".join(result)  # Join the OCR result into a single string\n        \n        # Use regex to find the value + unit (e.g., numbers followed by units like cm³, L, etc.)\n        pattern = r'(\\d+\\.?\\d*)\\s?(cm³|liters|ml|g|kg|m³|in³|L|oz|fl oz)'  # Modify as per expected units\n        matches = re.findall(pattern, extracted_text)\n        pattern = r'(\\d+)\\s*(mL)'\n        matches = re.findall(pattern,extracted_text)\n\n        if matches:\n            # Return the first match (value + unit)\n            return f\"{matches[0][0]} {matches[0][1]}\"\n        else:\n            # Return blank if no match is found\n            return \" \"\n    \n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return \" \"  # Return blank in case of an error\n\n# Assuming you already have the item_volume dataframe (df_item_volume)\ndf_item_volume = pd.DataFrame({\n    'index': [128522, 128501, 115029, 41358, 112194],\n    'image_link': [\n        \"https://m.media-amazon.com/images/I/81bgTNB4g-L._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/81bLHedrwL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/711dIDwDuJ._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/51MVfM5NJV._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61jCNOENUwL._AC_SL1500_.jpg\"\n    ],\n    'group_id': [257505, 426449, 142295, 588284, 784861],\n    'entity_name': ['item_volume', 'item_volume', 'item_volume', 'item_volume', 'item_volume']\n})\n\n# Create a new column to store the extracted item volume (value + unit)\ndf_item_volume['prediction'] = df_item_volume['image_link'].apply(extract_value_unit_from_image)\n\n# Display the updated DataFrame\nprint(df_item_volume[[\"index\",'prediction']])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:14:34.657927Z","iopub.execute_input":"2024-09-14T12:14:34.658388Z","iopub.status.idle":"2024-09-14T12:14:41.303700Z","shell.execute_reply.started":"2024-09-14T12:14:34.658347Z","shell.execute_reply":"2024-09-14T12:14:41.302599Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Error downloading image from https://m.media-amazon.com/images/I/81bLHedrwL._AC_SL1500_.jpg: 400 Client Error: Bad Request for url: https://m.media-amazon.com/images/I/81bLHedrwL._AC_SL1500_.jpg\nError downloading image from https://m.media-amazon.com/images/I/711dIDwDuJ._AC_SL1500_.jpg: 400 Client Error: Bad Request for url: https://m.media-amazon.com/images/I/711dIDwDuJ._AC_SL1500_.jpg\nError downloading image from https://m.media-amazon.com/images/I/51MVfM5NJV._AC_SL1500_.jpg: 400 Client Error: Bad Request for url: https://m.media-amazon.com/images/I/51MVfM5NJV._AC_SL1500_.jpg\n    index prediction\n0  128522     946 mL\n1  128501           \n2  115029           \n3   41358           \n4  112194           \n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport numpy as np\nimport pandas as pd\nimport easyocr\nimport re\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=False)\n\n# Function to preprocess and perform OCR on the image URL\ndef extract_value_unit_from_image(image_url):\n    try:\n        # Send a request to get the image from the URL\n        response = requests.get(image_url)\n        response.raise_for_status()  # Ensure the request was successful\n\n        # Open the image and convert it to grayscale\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Convert Pillow image to numpy array for OCR\n        np_image = np.array(gray_img)\n        \n        # Perform OCR using EasyOCR\n        result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n        extracted_text = \" \".join(result)  # Join the OCR result into a single string\n        \n        # Use regex to find the value + unit (e.g., numbers followed by units like cm³, L, etc.)\n        pattern = r'(\\d+\\.?\\d*)\\s?(cm³|liters|ml|g|kg|m³|in³|L|oz|fl oz)'  # Modify as per expected units\n        matches = re.findall(pattern, extracted_text, re.IGNORECASE)\n        \n        if matches:\n            # Return the first match (value + unit)\n            return f\"{matches[0][0]} {matches[0][1]}\"\n        else:\n            # Return blank if no match is found\n            return \" \"\n    \n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return \" \"  # Return blank in case of an error\n\n# Create a DataFrame (this is an example, replace it with your actual data loading)\ndf_item_volume = pd.DataFrame({\n    'index': [128522, 128501, 115029, 41358, 112194, 114978, 127232, 127456, 112191],\n    'image_link': [\n        \"https://m.media-amazon.com/images/I/81bgTNB4g-L.jpg\",\n        \"https://m.media-amazon.com/images/I/81bLHedrwL.jpg\",\n        \"https://m.media-amazon.com/images/I/711dIDwDuJ.jpg\",\n        \"https://m.media-amazon.com/images/I/51MVfM5NJV.jpg\",\n        \"https://m.media-amazon.com/images/I/61jCNOENUwL.jpg\",\n        \"https://m.media-amazon.com/images/I/711EbPu-Nh.jpg\",\n        \"https://m.media-amazon.com/images/I/81KOZGbVZB.jpg\",\n        \"https://m.media-amazon.com/images/I/81N6CnmBpr.jpg\",\n        \"https://m.media-amazon.com/images/I/61j9aDDdjD.jpg\"\n    ],\n    'group_id': [257505, 426449, 142295, 588284, 784861, 417442, 125148, 162326, 472418],\n    'entity_name': ['item_volume'] * 9\n})\n\n# Create a new column to store the extracted item volume (value + unit)\ndf_item_volume['prediction'] = df_item_volume['image_link'].apply(extract_value_unit_from_image)\n\n# Save the updated DataFrame to a CSV file\noutput_file = 'item_volume_predictions.csv'\ndf_item_volume.to_csv(output_file, index=False)\n\nprint(f\"DataFrame with predictions saved to {output_file}\")\n\n# Display the updated DataFrame\nprint(df_item_volume[[\"index\", \"prediction\"]])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.254961Z","iopub.status.idle":"2024-09-14T12:13:00.255346Z","shell.execute_reply.started":"2024-09-14T12:13:00.255167Z","shell.execute_reply":"2024-09-14T12:13:00.255187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport numpy as np\nimport pandas as pd\nimport easyocr\nimport re\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=False)\n\n# Function to preprocess and perform OCR on the image URL\ndef extract_value_unit_from_image(image_url):\n    try:\n        # Send a request to get the image from the URL\n        response = requests.get(image_url)\n        response.raise_for_status()  # Ensure the request was successful\n\n        # Open the image and convert it to grayscale\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Convert Pillow image to numpy array for OCR\n        np_image = np.array(gray_img)\n        \n        # Perform OCR using EasyOCR\n        result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n        extracted_text = \" \".join(result)  # Join the OCR result into a single string\n        \n        # Use regex to find the value + unit (e.g., numbers followed by units like cm³, L, etc.)\n        pattern = r'(\\d+\\.?\\d*)\\s?(cm³|liters|ml|g|kg|m³|in³|L|oz|fl oz)'  # Modify as per expected units\n        matches = re.findall(pattern, extracted_text, re.IGNORECASE)\n        \n        if matches:\n            # Return the first match (value + unit)\n            return f\"{matches[0][0]} {matches[0][1]}\"\n        else:\n            # Return blank if no match is found\n            return \" \"\n    \n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return \" \"  # Return blank in case of an error\n\n# DataFrame of image URLs\ndf_item_volume = pd.DataFrame({\n    'index': [128522, 128501, 115029, 41358, 112194, 114978, 127232, 127456, 112191],\n    'image_link': [\n        \"https://m.media-amazon.com/images/I/81bgTNB4g-L._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/81bLHedrwLL._AC_SL1500_.jpg\",  # Corrected URL\n        \"https://m.media-amazon.com/images/I/711dIDwDuJL._AC_SL1500_.jpg\",  # Corrected URL\n        \"https://m.media-amazon.com/images/I/51MVfM5NJVTL._AC_SL1500_.jpg\",  # Corrected URL\n        \"https://m.media-amazon.com/images/I/61jCNOENUwL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/711EbPu-NhLL._AC_SL1500_.jpg\",  # Corrected URL\n        \"https://m.media-amazon.com/images/I/81KOZGbVZBL._AC_SL1500_.jpg\",  # Corrected URL\n        \"https://m.media-amazon.com/images/I/81N6CnmBprL._AC_SL1500_.jpg\",  # Corrected URL\n        \"https://m.media-amazon.com/images/I/61j9aDDdjDL._AC_SL1500_.jpg\"   # Corrected URL\n    ],\n    'group_id': [257505, 426449, 142295, 588284, 784861, 417442, 125148, 162326, 472418],\n    'entity_name': ['item_volume'] * 9\n})\n\n# Create a new column to store the extracted item volume (value + unit)\ndf_item_volume['prediction'] = df_item_volume['image_link'].apply(extract_value_unit_from_image)\n\n# Save the updated DataFrame to a CSV file\noutput_file = 'item_volume_predictions.csv'\ndf_item_volume.to_csv(output_file, index=False)\n\nprint(f\"DataFrame with predictions saved to {output_file}\")\n\n# Display the updated DataFrame\nprint(df_item_volume[[\"index\", \"prediction\"]])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.257007Z","iopub.status.idle":"2024-09-14T12:13:00.257550Z","shell.execute_reply.started":"2024-09-14T12:13:00.257268Z","shell.execute_reply":"2024-09-14T12:13:00.257295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport numpy as np\nimport pandas as pd\nimport easyocr\nimport re\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=False)\n\n# Function to preprocess and perform OCR on the image URL\ndef extract_value_unit_from_image(image_url):\n    try:\n        # Send a request to get the image from the URL\n        response = requests.get(image_url)\n        response.raise_for_status()  # Ensure the request was successful\n\n        # Open the image and convert it to grayscale\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Convert Pillow image to numpy array for OCR\n        np_image = np.array(gray_img)\n        \n        # Perform OCR using EasyOCR\n        result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n        extracted_text = \" \".join(result)  # Join the OCR result into a single string\n        \n        # Use regex to find the value + unit (e.g., numbers followed by units like cm³, L, etc.)\n        pattern = r'(\\d+\\.?\\d*)\\s?(cm³|liters|ml|g|kg|m³|in³|L|oz|fl oz)'  # Modify as per expected units\n        matches = re.findall(pattern, extracted_text, re.IGNORECASE)\n        \n        if matches:\n            # Return the first match (value + unit)\n            return f\"{matches[0][0]} {matches[0][1]}\"\n        else:\n            # Return blank if no match is found\n            return \" \"\n    \n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return \" \"  # Return blank in case of an error\n\ndf_item_volume = pd.DataFrame({\n    'index': [45081, 127477, 111793, 112234, 114989, 128678, 111771, 121564, 111742, 63256, 112264],\n    'image_link': [\n        \"https://m.media-amazon.com/images/I/51Qb3xsnqjL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/81NLC-MbzNL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61g-R0dUWvL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61jWtTCGOFL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/711JmTEgBUL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/81dup5ucjWL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61fwkjqJ0mL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/71cjjOrq97L._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61fn0eiL6FL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/51kWTG56JdL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61jnmb4d4JL._AC_SL1500_.jpg\"\n    ],\n    'group_id': [961822, 911827, 373285, 588284, 692827, 976920, 941694, 142295, 287137, 941694, 693967],\n    'entity_name': ['item_volume'] * 11\n})\n\n# Create a new column to store the extracted item volume (value + unit)\ndf_item_volume['prediction'] = df_item_volume['image_link'].apply(extract_value_unit_from_image)\n\n# Save the updated DataFrame to a CSV file\noutput_file = 'item_volume_predictions.csv'\ndf_item_volume.to_csv(output_file, index=False)\n\nprint(f\"DataFrame with predictions saved to {output_file}\")\n\n# Display the updated DataFrame\nprint(df_item_volume[[\"index\", \"prediction\"]])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.259016Z","iopub.status.idle":"2024-09-14T12:13:00.259560Z","shell.execute_reply.started":"2024-09-14T12:13:00.259273Z","shell.execute_reply":"2024-09-14T12:13:00.259299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_item_volume = pd.DataFrame({\n    'index': [45081, 127477, 111793, 112234, 114989, 128678, 111771, 121564, 111742, 63256, 112264],\n    'image_link': [\n        \"https://m.media-amazon.com/images/I/51Qb3xsnqjL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/81NLC-MbzNL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61g-R0dUWvL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61jWtTCGOFL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/711JmTEgBUL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/81dup5ucjWL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61fwkjqJ0mL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/71cjjOrq97L._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61fn0eiL6FL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/51kWTG56JdL._AC_SL1500_.jpg\",\n        \"https://m.media-amazon.com/images/I/61jnmb4d4JL._AC_SL1500_.jpg\"\n    ],\n    'group_id': [961822, 911827, 373285, 588284, 692827, 976920, 941694, 142295, 287137, 941694, 693967],\n    'entity_name': ['item_volume'] * 11\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.260842Z","iopub.status.idle":"2024-09-14T12:13:00.261329Z","shell.execute_reply.started":"2024-09-14T12:13:00.261115Z","shell.execute_reply":"2024-09-14T12:13:00.261143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPU100 ACCELERETOR","metadata":{}},{"cell_type":"markdown","source":"> Explanation\n\n# Load Dataset with Index: \n* When reading the CSV, index_col=0 ensures that the first column of your CSV is used as the DataFrame index. Adjust index_col based on the actual column in your CSV that contains the index.\n\n# Extract Volume: \n* The extract_value_unit_from_image function is applied to each image URL.\n\n# Create Output DataFrame:\n* The new DataFrame output_df contains only the prediction column and retains the original index from your dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport numpy as np\nimport easyocr\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=True)\n\ndef extract_volume(text):\n    # Improved regular expression pattern for item volumes\n    volume_pattern = r\"(\\d+\\.?\\d*)\\s?(mL|ml|liters|L|fl oz|FL 0z|FL oz|oz|cm³|in³|cubic inches|cubic cm)\"\n    \n    # Search for all matches in the text\n    matches = re.findall(volume_pattern, text, re.IGNORECASE)\n    \n    # Prepare a list to store formatted volumes\n    volumes = []\n    \n    # Process each match to clean up the format\n    for match in matches:\n        volume_value, volume_unit = match\n        volume_value = volume_value.strip()  # Remove extra spaces\n        volume_unit = volume_unit.lower()    # Normalize units to lower case\n        volumes.append(f\"{volume_value} {volume_unit}\")\n\n    # Return list of extracted volumes\n    return volumes\n\ndef extract_value_unit_from_image(image_url):\n    try:\n        # Download and preprocess the image\n        response = requests.get(image_url)\n        response.raise_for_status()\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Convert Pillow image to numpy array\n        np_image = np.array(gray_img)\n        \n        # Perform OCR using EasyOCR\n        result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n        extracted_text = \" \".join(result)\n        \n        # Extract volumes from the OCR result\n        volumes = extract_volume(extracted_text)\n        return volumes\n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return []\n\n# Load your full dataset\ndf_item_volume = pd.read_csv('/kaggle/working/item_volume_data.csv', index_col=0)  # Assuming the index column is the first column\n\n# Apply the function to the 'image_link' column\ndf_item_volume['prediction'] = df_item_volume['image_link'].apply(extract_value_unit_from_image)\n\n# Create a new DataFrame with only the index and prediction columns\noutput_df = df_item_volume[['prediction']].copy()\noutput_df.index.name = 'index'  # Ensure the index name is set\n\n# Save the updated DataFrame with predictions to a new CSV file\noutput_df.to_csv('/kaggle/working/item_volume_predictions_final.csv', index=True)\n\n# Display the head of the updated DataFrame to confirm predictions\nprint(output_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:27:07.617758Z","iopub.execute_input":"2024-09-14T12:27:07.618887Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_volume.tail()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.264565Z","iopub.status.idle":"2024-09-14T12:13:00.264924Z","shell.execute_reply.started":"2024-09-14T12:13:00.264746Z","shell.execute_reply":"2024-09-14T12:13:00.264765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom PIL import Image, ImageOps\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport easyocr\n\n# Initialize EasyOCR reader\nreader = easyocr.Reader(['en'], gpu=False)\n\n# Sample image URL\nimage_url = \"https://m.media-amazon.com/images/I/61jWtTCGOFL._AC_SL1500_.jpg\"\n\n# Function to preprocess and display the image\ndef preprocess_image(image_url):\n    try:\n        # Send a request to get the image from the URL\n        response = requests.get(image_url)\n        response.raise_for_status()  # Ensure the request was successful\n        \n        # Open the image and convert it to grayscale\n        img = Image.open(BytesIO(response.content))\n        gray_img = ImageOps.grayscale(img)\n        \n        # Display the image\n        plt.imshow(gray_img, cmap='gray')\n        plt.axis('off')  # Turn off the axis\n        plt.show()\n        \n        return gray_img\n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {image_url}: {e}\")\n        return None\n\n# Preprocess and display the image\npreprocessed_image = preprocess_image(image_url)\n\n# Perform OCR if the image was processed successfully\nif preprocessed_image:\n    # Convert Pillow image to numpy array\n    np_image = np.array(preprocessed_image)\n    \n    # Perform OCR using EasyOCR\n    result = reader.readtext(np_image, detail=0)  # detail=0 returns only the text\n    extracted_text = \" \".join(result)  # Join the OCR result into a single string\n    print(extracted_text)\nelse:\n    print(\"Error processing image\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.266187Z","iopub.status.idle":"2024-09-14T12:13:00.266604Z","shell.execute_reply.started":"2024-09-14T12:13:00.266398Z","shell.execute_reply":"2024-09-14T12:13:00.266419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef extract_volume(text):\n    # Regular expression pattern to match item volumes (e.g., \"32 fl oz\", \"946 mL\", \"1.5 liters\", \"250 cm³\")\n    volume_pattern = r\"(\\d+\\.?\\d*)\\s?(mL|ml|liters|L|fl oz|FL 0z|oz|cm³|in³|cubic inches|cubic cm)\"\n    \n    # Search for all matches in the text\n    matches = re.findall(volume_pattern, text, re.IGNORECASE)\n    \n    # Prepare a list to store formatted volumes\n    volumes = []\n    \n    # Process each match to clean up the format\n    for match in matches:\n        volume_value, volume_unit = match\n        volume_value = volume_value.strip()  # Remove extra spaces\n        volume_unit = volume_unit.lower()    # Normalize units to lower case\n        volumes.append(f\"{volume_value} {volume_unit}\")\n\n    # Return list of extracted volumes\n    return volumes\n\nimport re\n\ntext = \"& AX VS 4X 'OKupoarduow 6 4 ML) [6len (946 Foncs POND Mirkqe Scrnces CLEANER AX MUCK  MORE NATURAL 'REMOVER CONCENTRATED SLUDGE / TREATS L AwakaT 32FL 0z Uerkhoia Jemu FOR SAFEF\"\npattern = r'(\\d+)\\s*(FL 0z)'\nmatches = re.findall(pattern, text)\n\nvolumes = [f\"{match[0]} {match[1]}\" for match in matches]\nprint(\"Extracted Volumes:\", volumes)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.269334Z","iopub.status.idle":"2024-09-14T12:13:00.269838Z","shell.execute_reply.started":"2024-09-14T12:13:00.269580Z","shell.execute_reply":"2024-09-14T12:13:00.269607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef extract_total_ml(text):\n    # Regular expression to find values in various formats\n    pattern = r'\\b\\d+(\\.\\d+)?\\s?ml\\b'\n    matches = re.findall(pattern, text, re.IGNORECASE)\n    \n    # Convert matches to float and sum them up\n    total_volume = sum(float(match.replace(',', '.')) for match in matches)\n    \n    return f\"{total_volume:.1f} ml\"\n\n# Example text\ntext = \"\"\"FOOD GRADE VEGAN MSDS AOCOCOLORING Fu_COLORING HCOCOLORING OREEN Red SkY BLUE MWT: IOML (0.35021 | FMT: TOML (0,3502) FFTWT: IOML (0,3502) FLdD COLORING ORING XUCOLORLNG '6UCOLORING MSDS MSDS MSDS FLI DCOLORING FcJO COLORING HAvy BLUE KSUNSET VELLOH RASS CREEN PINK BROWN VETMT: TOML (0.3502] IOML (0,3502) JM: TOML (0.3507) Lik IOML (0.3502] IETWT: IOML (0,35021 DS MSDS 50s 2 1 3 3 1 Gluten Free Nut Free Sugar Free Egg Free Dairy Free Free 8 1 I 1 { 0 ( 0 { 8 Soy\"\"\"\n\n# Extract total ml\ntotal_ml = extract_total_ml(text)\nprint(total_ml)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.270993Z","iopub.status.idle":"2024-09-14T12:13:00.271523Z","shell.execute_reply.started":"2024-09-14T12:13:00.271257Z","shell.execute_reply":"2024-09-14T12:13:00.271284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the 'depth_data.csv' file\nitem_volume_df = pd.read_csv('item_volume_data.csv')\n\n# Display the top 5 rows of the 'depth_data.csv'\nprint(item_volume_df.head(100))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.273069Z","iopub.status.idle":"2024-09-14T12:13:00.273572Z","shell.execute_reply.started":"2024-09-14T12:13:00.273311Z","shell.execute_reply":"2024-09-14T12:13:00.273337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndf = pd.read_csv('/kaggle/input/real-test-data/dataset/test.csv')\n\n# Create a new DataFrame with only the 'index' column\ndf_new = df[['index']].copy()\n\n# Add a new column 'prediction' with blank values\ndf_new['prediction'] = \" \"  # Ensure all values are blank\n\n# Optionally, save the new DataFrame to a new CSV file\ndf_new.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.275018Z","iopub.status.idle":"2024-09-14T12:13:00.275536Z","shell.execute_reply.started":"2024-09-14T12:13:00.275276Z","shell.execute_reply":"2024-09-14T12:13:00.275305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new.tail()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.277795Z","iopub.status.idle":"2024-09-14T12:13:00.278346Z","shell.execute_reply.started":"2024-09-14T12:13:00.278048Z","shell.execute_reply":"2024-09-14T12:13:00.278076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss=pd.read_csv(\"/kaggle/input/real-test-data/dataset/test.csv\")\nss.tail()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:13:00.280239Z","iopub.status.idle":"2024-09-14T12:13:00.280732Z","shell.execute_reply.started":"2024-09-14T12:13:00.280468Z","shell.execute_reply":"2024-09-14T12:13:00.280495Z"},"trusted":true},"execution_count":null,"outputs":[]}]}